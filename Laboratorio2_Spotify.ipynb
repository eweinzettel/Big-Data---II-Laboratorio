{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Laboratorio 2**\n",
        "\n",
        "**Clasificador de canciones de Spotify**\n",
        "\n",
        "Grupo 30:\n",
        "\n",
        "• Aniñir Lionel\n",
        "\n",
        "• Leal Patricia Guillermina\n",
        "\n",
        "• Weinzettel Eduardo"
      ],
      "metadata": {
        "id": "p6YkHQyvkWrZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importar bibliotecas necesarias\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB"
      ],
      "metadata": {
        "id": "7bJTrnxPr0PY"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UkfK84qhBO4P",
        "outputId": "4ffe07ce-c473-4603-e475-35960373be42"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar el conjunto de datos desde el archivo CSV\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/BIG DATA/LABORATORIO II/Canciones_Spotify.csv\")\n",
        "\n",
        "# Mostrar las primeras filas del DataFrame para entender la estructura de los datos\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 686
        },
        "id": "I8Dl_Ee0zTut",
        "outputId": "e39a6bac-9780-485c-8fc1-71dfff2fc14d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Unnamed: 0  acousticness  danceability  duration_ms  energy  \\\n",
              "0              0       0.01020         0.833       204600   0.434   \n",
              "1              1       0.19900         0.743       326933   0.359   \n",
              "2              2       0.03440         0.838       185707   0.412   \n",
              "3              3       0.60400         0.494       199413   0.338   \n",
              "4              4       0.18000         0.678       392893   0.561   \n",
              "...          ...           ...           ...          ...     ...   \n",
              "2012        2012       0.00106         0.584       274404   0.932   \n",
              "2013        2013       0.08770         0.894       182182   0.892   \n",
              "2014        2014       0.00857         0.637       207200   0.935   \n",
              "2015        2015       0.00164         0.557       185600   0.992   \n",
              "2016        2016       0.00281         0.446       204520   0.915   \n",
              "\n",
              "      instrumentalness  key  liveness  loudness  mode  speechiness    tempo  \\\n",
              "0             0.021900    2    0.1650    -8.795     1       0.4310  150.062   \n",
              "1             0.006110    1    0.1370   -10.401     1       0.0794  160.083   \n",
              "2             0.000234    2    0.1590    -7.148     1       0.2890   75.044   \n",
              "3             0.510000    5    0.0922   -15.236     1       0.0261   86.468   \n",
              "4             0.512000    5    0.4390   -11.648     0       0.0694  174.004   \n",
              "...                ...  ...       ...       ...   ...          ...      ...   \n",
              "2012          0.002690    1    0.1290    -3.501     1       0.3330   74.976   \n",
              "2013          0.001670    1    0.0528    -2.663     1       0.1310  110.041   \n",
              "2014          0.003990    0    0.2140    -2.467     1       0.1070  150.082   \n",
              "2015          0.677000    1    0.0913    -2.735     1       0.1330  150.011   \n",
              "2016          0.000039    9    0.2180    -6.221     1       0.1410  190.013   \n",
              "\n",
              "      time_signature  valence  target                            song_title  \\\n",
              "0                4.0    0.286       1                              Mask Off   \n",
              "1                4.0    0.588       1                               Redbone   \n",
              "2                4.0    0.173       1                          Xanny Family   \n",
              "3                4.0    0.230       1                        Master Of None   \n",
              "4                4.0    0.904       1                        Parallel Lines   \n",
              "...              ...      ...     ...                                   ...   \n",
              "2012             4.0    0.211       0   Like A Bitch - Kill The Noise Remix   \n",
              "2013             4.0    0.867       0                                 Candy   \n",
              "2014             4.0    0.470       0  Habit - Dack Janiels & Wenzday Remix   \n",
              "2015             4.0    0.623       0                         First Contact   \n",
              "2016             4.0    0.402       0                    I Wanna Get Better   \n",
              "\n",
              "                artist  \n",
              "0               Future  \n",
              "1     Childish Gambino  \n",
              "2               Future  \n",
              "3          Beach House  \n",
              "4          Junior Boys  \n",
              "...                ...  \n",
              "2012    Kill The Noise  \n",
              "2013    Dillon Francis  \n",
              "2014          Rain Man  \n",
              "2015        Twin Moons  \n",
              "2016         Bleachers  \n",
              "\n",
              "[2017 rows x 17 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bd7baae3-f069-4c2b-8c47-8a520907ae68\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>acousticness</th>\n",
              "      <th>danceability</th>\n",
              "      <th>duration_ms</th>\n",
              "      <th>energy</th>\n",
              "      <th>instrumentalness</th>\n",
              "      <th>key</th>\n",
              "      <th>liveness</th>\n",
              "      <th>loudness</th>\n",
              "      <th>mode</th>\n",
              "      <th>speechiness</th>\n",
              "      <th>tempo</th>\n",
              "      <th>time_signature</th>\n",
              "      <th>valence</th>\n",
              "      <th>target</th>\n",
              "      <th>song_title</th>\n",
              "      <th>artist</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.01020</td>\n",
              "      <td>0.833</td>\n",
              "      <td>204600</td>\n",
              "      <td>0.434</td>\n",
              "      <td>0.021900</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1650</td>\n",
              "      <td>-8.795</td>\n",
              "      <td>1</td>\n",
              "      <td>0.4310</td>\n",
              "      <td>150.062</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.286</td>\n",
              "      <td>1</td>\n",
              "      <td>Mask Off</td>\n",
              "      <td>Future</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.19900</td>\n",
              "      <td>0.743</td>\n",
              "      <td>326933</td>\n",
              "      <td>0.359</td>\n",
              "      <td>0.006110</td>\n",
              "      <td>1</td>\n",
              "      <td>0.1370</td>\n",
              "      <td>-10.401</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0794</td>\n",
              "      <td>160.083</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.588</td>\n",
              "      <td>1</td>\n",
              "      <td>Redbone</td>\n",
              "      <td>Childish Gambino</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.03440</td>\n",
              "      <td>0.838</td>\n",
              "      <td>185707</td>\n",
              "      <td>0.412</td>\n",
              "      <td>0.000234</td>\n",
              "      <td>2</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>-7.148</td>\n",
              "      <td>1</td>\n",
              "      <td>0.2890</td>\n",
              "      <td>75.044</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.173</td>\n",
              "      <td>1</td>\n",
              "      <td>Xanny Family</td>\n",
              "      <td>Future</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.60400</td>\n",
              "      <td>0.494</td>\n",
              "      <td>199413</td>\n",
              "      <td>0.338</td>\n",
              "      <td>0.510000</td>\n",
              "      <td>5</td>\n",
              "      <td>0.0922</td>\n",
              "      <td>-15.236</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0261</td>\n",
              "      <td>86.468</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.230</td>\n",
              "      <td>1</td>\n",
              "      <td>Master Of None</td>\n",
              "      <td>Beach House</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.18000</td>\n",
              "      <td>0.678</td>\n",
              "      <td>392893</td>\n",
              "      <td>0.561</td>\n",
              "      <td>0.512000</td>\n",
              "      <td>5</td>\n",
              "      <td>0.4390</td>\n",
              "      <td>-11.648</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0694</td>\n",
              "      <td>174.004</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.904</td>\n",
              "      <td>1</td>\n",
              "      <td>Parallel Lines</td>\n",
              "      <td>Junior Boys</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2012</th>\n",
              "      <td>2012</td>\n",
              "      <td>0.00106</td>\n",
              "      <td>0.584</td>\n",
              "      <td>274404</td>\n",
              "      <td>0.932</td>\n",
              "      <td>0.002690</td>\n",
              "      <td>1</td>\n",
              "      <td>0.1290</td>\n",
              "      <td>-3.501</td>\n",
              "      <td>1</td>\n",
              "      <td>0.3330</td>\n",
              "      <td>74.976</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.211</td>\n",
              "      <td>0</td>\n",
              "      <td>Like A Bitch - Kill The Noise Remix</td>\n",
              "      <td>Kill The Noise</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2013</th>\n",
              "      <td>2013</td>\n",
              "      <td>0.08770</td>\n",
              "      <td>0.894</td>\n",
              "      <td>182182</td>\n",
              "      <td>0.892</td>\n",
              "      <td>0.001670</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0528</td>\n",
              "      <td>-2.663</td>\n",
              "      <td>1</td>\n",
              "      <td>0.1310</td>\n",
              "      <td>110.041</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.867</td>\n",
              "      <td>0</td>\n",
              "      <td>Candy</td>\n",
              "      <td>Dillon Francis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2014</th>\n",
              "      <td>2014</td>\n",
              "      <td>0.00857</td>\n",
              "      <td>0.637</td>\n",
              "      <td>207200</td>\n",
              "      <td>0.935</td>\n",
              "      <td>0.003990</td>\n",
              "      <td>0</td>\n",
              "      <td>0.2140</td>\n",
              "      <td>-2.467</td>\n",
              "      <td>1</td>\n",
              "      <td>0.1070</td>\n",
              "      <td>150.082</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.470</td>\n",
              "      <td>0</td>\n",
              "      <td>Habit - Dack Janiels &amp; Wenzday Remix</td>\n",
              "      <td>Rain Man</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2015</th>\n",
              "      <td>2015</td>\n",
              "      <td>0.00164</td>\n",
              "      <td>0.557</td>\n",
              "      <td>185600</td>\n",
              "      <td>0.992</td>\n",
              "      <td>0.677000</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0913</td>\n",
              "      <td>-2.735</td>\n",
              "      <td>1</td>\n",
              "      <td>0.1330</td>\n",
              "      <td>150.011</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.623</td>\n",
              "      <td>0</td>\n",
              "      <td>First Contact</td>\n",
              "      <td>Twin Moons</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2016</th>\n",
              "      <td>2016</td>\n",
              "      <td>0.00281</td>\n",
              "      <td>0.446</td>\n",
              "      <td>204520</td>\n",
              "      <td>0.915</td>\n",
              "      <td>0.000039</td>\n",
              "      <td>9</td>\n",
              "      <td>0.2180</td>\n",
              "      <td>-6.221</td>\n",
              "      <td>1</td>\n",
              "      <td>0.1410</td>\n",
              "      <td>190.013</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.402</td>\n",
              "      <td>0</td>\n",
              "      <td>I Wanna Get Better</td>\n",
              "      <td>Bleachers</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2017 rows × 17 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bd7baae3-f069-4c2b-8c47-8a520907ae68')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bd7baae3-f069-4c2b-8c47-8a520907ae68 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bd7baae3-f069-4c2b-8c47-8a520907ae68');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-13f8de86-c1a5-41e5-83ff-da71ed204548\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-13f8de86-c1a5-41e5-83ff-da71ed204548')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-13f8de86-c1a5-41e5-83ff-da71ed204548 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler, LabelEncoder #Importar biblioteca necesaria\n",
        "\n",
        "# Eliminar columnas innecesarias y manejar variables categóricas\n",
        "data = data.drop(columns=[\"Unnamed: 0\", \"song_title\", \"artist\"])\n",
        "label_encoder = LabelEncoder()\n",
        "data[\"target\"] = label_encoder.fit_transform(data[\"target\"])\n",
        "# Usamos LabelEncoder para convertir la variable objetivo ('target') en valores numéricos.\n",
        "# Esto es necesario para que los modelos de Machine Learning puedan trabajar con la variable objetivo.\n",
        "\n",
        "# Separar características (X) y etiquetas (y)\n",
        "X = data.drop(columns=[\"target\"]) # X contiene las características, que son todas las columnas excepto 'target'.\n",
        "y = data[\"target\"] # y contiene la variable objetivo, que es la columna 'target'.\n",
        "\n",
        "# Escalar características numéricas\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "# Estandarizamos las características numéricas para que tengan una media de 0 y una desviación estándar de 1.\n",
        "# Esto es importante para modelos como SVM y KNN, que son sensibles a la escala de las características.\n",
        "\n",
        "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "# Dividimos los datos en un conjunto de entrenamiento (80%) y un conjunto de prueba (20%).\n",
        "# El parámetro random_state=42 asegura que la división sea reproducible, utilizando la misma semilla aleatoria cada vez que se ejecuta el código.\n",
        "\n",
        "# En este punto, hemos preparado los datos para entrenar y evaluar los modelos de Machine Learning."
      ],
      "metadata": {
        "id": "_p34go3U28D0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KNN (K-Nearest Neighbors)"
      ],
      "metadata": {
        "id": "7QaIL7Tx6kav"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "El algoritmo KNN es un método de aprendizaje supervisado que se utiliza para clasificación y regresión. Funciona buscando las k observaciones más similares en el conjunto de entrenamiento para una nueva observación y realiza una predicción basada en sus vecinos más cercanos.\n",
        "\n",
        "Primero, entrenamos un modelo KNN con los datos de entrenamiento y luego evaluamos su rendimiento utilizando diferentes métricas.\n",
        "\n",
        "Inicialización del clasificador KNN: Creamos un clasificador KNN con 5 vecinos más cercanos. Este número de vecinos es un valor arbitrario y puede ser ajustado según sea necesario.\n",
        "Entrenamiento del modelo: El modelo se entrena utilizando los datos de entrenamiento (X_train y y_train). Durante el entrenamiento, el modelo aprende los patrones presentes en los datos.\n",
        "Predicciones: Utilizamos el modelo entrenado para hacer predicciones sobre el conjunto de prueba (X_test). Estas predicciones se almacenan en y_pred_knn.\n",
        "Evaluación del rendimiento: Calculamos la matriz de confusión y el informe de clasificación para evaluar el rendimiento del modelo KNN en el conjunto de prueba."
      ],
      "metadata": {
        "id": "ms3cOJ-W8AhP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# Inicializar el clasificador KNN con un valor de k arbitrario (por ejemplo, k=5)\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
        "# Usamos 5 vecinos más cercanos para hacer las predicciones.\n",
        "\n",
        "# Entrenar el modelo KNN con los datos de entrenamiento\n",
        "knn_classifier.fit(X_train, y_train)\n",
        "# El modelo se ajusta a los datos de entrenamiento, aprendiendo los patrones presentes en los datos.\n",
        "\n",
        "# Realizar predicciones en el conjunto de prueba\n",
        "y_pred_knn = knn_classifier.predict(X_test)\n",
        "# Usamos el modelo entrenado para hacer predicciones sobre el conjunto de prueba.\n",
        "\n",
        "# Evaluar el rendimiento del modelo KNN\n",
        "conf_matrix_knn = confusion_matrix(y_test, y_pred_knn)\n",
        "# Creamos una matriz de confusión para evaluar el rendimiento del modelo.\n",
        "# La matriz de confusión muestra la cantidad de verdaderos positivos, falsos positivos, verdaderos negativos y falsos negativos.\n",
        "\n",
        "class_report_knn = classification_report(y_test, y_pred_knn)\n",
        "# Creamos un informe de clasificación que incluye precision, recall y F1-score para evaluar el rendimiento del modelo.\n",
        "\n",
        "# Imprimir la matriz de confusión y el informe de clasificación del modelo KNN\n",
        "print(\"Matriz de Confusión (KNN):\")\n",
        "print(conf_matrix_knn)\n",
        "print(\"\\nInforme de Clasificación (KNN):\")\n",
        "print(class_report_knn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjsemhBn65gj",
        "outputId": "42b8c931-28f4-48e9-9ba2-bc20e1f9e220"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matriz de Confusión (KNN):\n",
            "[[158  48]\n",
            " [ 65 133]]\n",
            "\n",
            "Informe de Clasificación (KNN):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.77      0.74       206\n",
            "           1       0.73      0.67      0.70       198\n",
            "\n",
            "    accuracy                           0.72       404\n",
            "   macro avg       0.72      0.72      0.72       404\n",
            "weighted avg       0.72      0.72      0.72       404\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SVM (Support Vector Machines)"
      ],
      "metadata": {
        "id": "bO0qdKln6vLh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelo Support Vector Machines (SVM)\n",
        "SVM son un conjunto versátil de métodos de aprendizaje supervisado que se utilizan tanto para clasificación como para regresión. SVM funciona encontrando el hiperplano que mejor separa las clases en un espacio multidimensional. Podemos usar distintos kernel para SVM, como lineal, polinómico o radial (RBF). En este caso, usamos el kernel radial.\n",
        "\n",
        "Inicialización del clasificador SVM: Creamos un clasificador SVM con kernel radial. Utilizamos el kernel radial (RBF) porque es adecuado para datos que no tienen una frontera de decisión linealmente separable.\n",
        "Entrenamiento del modelo: El modelo se entrena utilizando los datos de entrenamiento (X_train y y_train). Durante el entrenamiento, el modelo encuentra el hiperplano que mejor separa las clases en el espacio multidimensional.\n",
        "Predicciones: Utilizamos el modelo entrenado para hacer predicciones sobre el conjunto de prueba (X_test). Estas predicciones se almacenan en y_pred_svm.\n",
        "Evaluación del rendimiento: Calculamos la matriz de confusión y el informe de clasificación para evaluar el rendimiento del modelo SVM en el conjunto de prueba."
      ],
      "metadata": {
        "id": "2MwaMdaD851H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializar el clasificador SVM con kernel radial\n",
        "svm_classifier = SVC(kernel='rbf', random_state=42)\n",
        "# Usamos el kernel radial ('rbf') para SVM.\n",
        "\n",
        "# Entrenar el modelo SVM con los datos de entrenamiento\n",
        "svm_classifier.fit(X_train, y_train)\n",
        "# El modelo se ajusta a los datos de entrenamiento, aprendiendo los patrones presentes en los datos.\n",
        "\n",
        "# Realizar predicciones en el conjunto de prueba\n",
        "y_pred_svm = svm_classifier.predict(X_test)\n",
        "# Usamos el modelo entrenado para hacer predicciones sobre el conjunto de prueba.\n",
        "\n",
        "# Evaluar el rendimiento del modelo SVM\n",
        "conf_matrix_svm = confusion_matrix(y_test, y_pred_svm)\n",
        "# Creamos una matriz de confusión para evaluar el rendimiento del modelo SVM.\n",
        "\n",
        "class_report_svm = classification_report(y_test, y_pred_svm)\n",
        "# Creamos un informe de clasificación que incluye precision, recall y F1-score para evaluar el rendimiento del modelo SVM.\n",
        "\n",
        "# Imprimir la matriz de confusión y el informe de clasificación del modelo SVM\n",
        "print(\"Matriz de Confusión (SVM):\")\n",
        "print(conf_matrix_svm)\n",
        "print(\"\\nInforme de Clasificación (SVM):\")\n",
        "print(class_report_svm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIEhDC2I66Fc",
        "outputId": "ff999e90-546c-4a9b-9f17-4287ab7d2c58"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matriz de Confusión (SVM):\n",
            "[[164  42]\n",
            " [ 64 134]]\n",
            "\n",
            "Informe de Clasificación (SVM):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.80      0.76       206\n",
            "           1       0.76      0.68      0.72       198\n",
            "\n",
            "    accuracy                           0.74       404\n",
            "   macro avg       0.74      0.74      0.74       404\n",
            "weighted avg       0.74      0.74      0.74       404\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Árbol de decisión"
      ],
      "metadata": {
        "id": "sW_O9gZo61Io"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelo Árbol de Decisión\n",
        "Los árboles de decisión son algoritmos de aprendizaje supervisado utilizados para clasificación y regresión. El modelo divide el conjunto de datos en subconjuntos más pequeños basados en ciertas características, haciendo preguntas sucesivas en cada nodo del árbol. Esto permite tomar decisiones basadas en las respuestas a esas preguntas.\n",
        "\n",
        "Inicialización del clasificador de Árbol de Decisión: Creamos un clasificador de Árbol de Decisión sin especificar hiperparámetros adicionales. En este caso, utilizamos los valores predeterminados del algoritmo.\n",
        "Entrenamiento del modelo: El modelo se entrena utilizando los datos de entrenamiento (X_train y y_train). Durante el entrenamiento, el modelo encuentra los patrones presentes en los datos utilizando preguntas basadas en las características.\n",
        "Predicciones: Utilizamos el modelo entrenado para hacer predicciones sobre el conjunto de prueba (X_test). Estas predicciones se almacenan en y_pred_decision_tree.\n",
        "Evaluación del rendimiento: Calculamos la matriz de confusión y el informe de clasificación para evaluar el rendimiento del modelo de Árbol de Decisión en el conjunto de prueba."
      ],
      "metadata": {
        "id": "CrSC87j6-QeV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializar el clasificador de Árbol de Decisión\n",
        "decision_tree_classifier = DecisionTreeClassifier(random_state=42)\n",
        "# No especificamos ningún hiperparámetro, utilizaremos los valores predeterminados.\n",
        "\n",
        "# Entrenar el modelo de Árbol de Decisión con los datos de entrenamiento\n",
        "decision_tree_classifier.fit(X_train, y_train)\n",
        "# El modelo se ajusta a los datos de entrenamiento, aprendiendo los patrones presentes en los datos.\n",
        "\n",
        "# Realizar predicciones en el conjunto de prueba\n",
        "y_pred_decision_tree = decision_tree_classifier.predict(X_test)\n",
        "# Usamos el modelo entrenado para hacer predicciones sobre el conjunto de prueba.\n",
        "\n",
        "# Evaluar el rendimiento del modelo de Árbol de Decisión\n",
        "conf_matrix_decision_tree = confusion_matrix(y_test, y_pred_decision_tree)\n",
        "# Creamos una matriz de confusión para evaluar el rendimiento del modelo de Árbol de Decisión.\n",
        "\n",
        "class_report_decision_tree = classification_report(y_test, y_pred_decision_tree)\n",
        "# Creamos un informe de clasificación que incluye precision, recall y F1-score para evaluar el rendimiento del modelo de Árbol de Decisión.\n",
        "\n",
        "# Imprimir la matriz de confusión y el informe de clasificación del modelo de Árbol de Decisión\n",
        "print(\"Matriz de Confusión (Árbol de Decisión):\")\n",
        "print(conf_matrix_decision_tree)\n",
        "print(\"\\nInforme de Clasificación (Árbol de Decisión):\")\n",
        "print(class_report_decision_tree)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hvn6z4x066Br",
        "outputId": "f71c748b-90ab-4e89-8243-3da8c6f96c1f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matriz de Confusión (Árbol de Decisión):\n",
            "[[148  58]\n",
            " [ 62 136]]\n",
            "\n",
            "Informe de Clasificación (Árbol de Decisión):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.70      0.72      0.71       206\n",
            "           1       0.70      0.69      0.69       198\n",
            "\n",
            "    accuracy                           0.70       404\n",
            "   macro avg       0.70      0.70      0.70       404\n",
            "weighted avg       0.70      0.70      0.70       404\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bayes (Naive Bayes)"
      ],
      "metadata": {
        "id": "02kb49wi65ld"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Modelo Naive Bayes\n",
        "Naive Bayes es un algoritmo de aprendizaje supervisado basado en el teorema de Bayes. A pesar de su simplicidad, a menudo se utiliza para problemas de clasificación de texto y tiene buenos resultados en diversas aplicaciones.\n",
        "Inicialización del clasificador Naive Bayes: Creamos un clasificador Naive Bayes utilizando el modelo Gaussian Naive Bayes, adecuado para características continuas como las nuestras.\n",
        "Entrenamiento del modelo: El modelo se entrena utilizando los datos de entrenamiento (X_train y y_train). Durante el entrenamiento, el modelo aprende los patrones presentes en los datos utilizando el teorema de Bayes.\n",
        "Predicciones: Utilizamos el modelo entrenado para hacer predicciones sobre el conjunto de prueba (X_test). Estas predicciones se almacenan en y_pred_naive_bayes.\n",
        "Evaluación del rendimiento: Calculamos la matriz de confusión y el informe de clasificación para evaluar el rendimiento del modelo Naive Bayes en el conjunto de prueba."
      ],
      "metadata": {
        "id": "WWKBdjQb_kD9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# Inicializar el clasificador Naive Bayes\n",
        "naive_bayes_classifier = GaussianNB()\n",
        "# Utilizamos el modelo Gaussian Naive Bayes, que es adecuado para características continuas como las nuestras.\n",
        "\n",
        "# Entrenar el modelo Naive Bayes con los datos de entrenamiento\n",
        "naive_bayes_classifier.fit(X_train, y_train)\n",
        "# El modelo se ajusta a los datos de entrenamiento, aprendiendo los patrones presentes en los datos.\n",
        "\n",
        "# Realizar predicciones en el conjunto de prueba\n",
        "y_pred_naive_bayes = naive_bayes_classifier.predict(X_test)\n",
        "# Usamos el modelo entrenado para hacer predicciones sobre el conjunto de prueba.\n",
        "\n",
        "# Evaluar el rendimiento del modelo Naive Bayes\n",
        "conf_matrix_naive_bayes = confusion_matrix(y_test, y_pred_naive_bayes)\n",
        "# Creamos una matriz de confusión para evaluar el rendimiento del modelo Naive Bayes.\n",
        "\n",
        "class_report_naive_bayes = classification_report(y_test, y_pred_naive_bayes)\n",
        "# Creamos un informe de clasificación que incluye precision, recall y F1-score para evaluar el rendimiento del modelo Naive Bayes.\n",
        "\n",
        "# Imprimir la matriz de confusión y el informe de clasificación del modelo Naive Bayes\n",
        "print(\"Matriz de Confusión (Naive Bayes):\")\n",
        "print(conf_matrix_naive_bayes)\n",
        "print(\"\\nInforme de Clasificación (Naive Bayes):\")\n",
        "print(class_report_naive_bayes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTuxsO5b65-e",
        "outputId": "c35dd533-fe48-4cd9-a19d-de9904bf1be0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matriz de Confusión (Naive Bayes):\n",
            "[[116  90]\n",
            " [ 58 140]]\n",
            "\n",
            "Informe de Clasificación (Naive Bayes):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.67      0.56      0.61       206\n",
            "           1       0.61      0.71      0.65       198\n",
            "\n",
            "    accuracy                           0.63       404\n",
            "   macro avg       0.64      0.64      0.63       404\n",
            "weighted avg       0.64      0.63      0.63       404\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Validación Cruzada k-fold"
      ],
      "metadata": {
        "id": "EFFblujG0b1K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Validación Cruzada k-fold\n",
        "La validación cruzada k-fold divide el conjunto de datos en k partes iguales, llamadas pliegues. El modelo se entrena k veces, utilizando k-1 pliegues para entrenamiento y 1 pliegue para validación en cada iteración. Luego se promedian los resultados de las k iteraciones para obtener una estimación más precisa del rendimiento del modelo.\n",
        "Utilizamos la función cross_val_score para realizar la validación cruzada k-fold para cada modelo (KNN, SVM, Naive Bayes) utilizando 5 pliegues (cv=5).\n",
        "El parámetro scoring='accuracy' indica que estamos interesados en medir la precisión del modelo durante la validación cruzada.\n",
        "Imprimimos los puntajes de validación cruzada obtenidos para cada modelo y calculamos la precisión promedio para evaluar el rendimiento general de cada modelo."
      ],
      "metadata": {
        "id": "o4p2sFiDAGQE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Realizar validación cruzada k-fold para el modelo KNN\n",
        "knn_scores = cross_val_score(knn_classifier, X_scaled, y, cv=5, scoring='accuracy')\n",
        "print(\"Puntajes de Validación Cruzada (KNN):\", knn_scores)\n",
        "print(\"Precisión Promedio (KNN):\", knn_scores.mean())\n",
        "\n",
        "# Realizar validación cruzada k-fold para el modelo SVM\n",
        "svm_scores = cross_val_score(svm_classifier, X_scaled, y, cv=5, scoring='accuracy')\n",
        "print(\"\\nPuntajes de Validación Cruzada (SVM):\", svm_scores)\n",
        "print(\"Precisión Promedio (SVM):\", svm_scores.mean())\n",
        "\n",
        "# Realizar validación cruzada k-fold para el modelo Naive Bayes\n",
        "naive_bayes_scores = cross_val_score(naive_bayes_classifier, X_scaled, y, cv=5, scoring='accuracy')\n",
        "print(\"\\nPuntajes de Validación Cruzada (Naive Bayes):\", naive_bayes_scores)\n",
        "print(\"Precisión Promedio (Naive Bayes):\", naive_bayes_scores.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FA3N_RB651h",
        "outputId": "6877ef24-0214-48b3-8300-32d131f5bb33"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Puntajes de Validación Cruzada (KNN): [0.7029703  0.65841584 0.5483871  0.66997519 0.67990074]\n",
            "Precisión Promedio (KNN): 0.6519298331818293\n",
            "\n",
            "Puntajes de Validación Cruzada (SVM): [0.75742574 0.70792079 0.5483871  0.69230769 0.69727047]\n",
            "Precisión Promedio (SVM): 0.6806623590398743\n",
            "\n",
            "Puntajes de Validación Cruzada (Naive Bayes): [0.5        0.62376238 0.4764268  0.58312655 0.52109181]\n",
            "Precisión Promedio (Naive Bayes): 0.5408815075055893\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimización de Hiperparámetros.\n",
        "\n",
        "Grid Search.\n",
        "\n",
        "Grid Search es una técnica que evalúa exhaustivamente una cuadrícula predefinida de hiperparámetros para encontrar la combinación óptima. En este caso, vamos a usar Grid Search para los modelos KNN y SVM.\n",
        "Definimos una cuadrícula de hiperparámetros para KNN, incluyendo el número de vecinos (n_neighbors), los pesos (weights) y la métrica de distancia (metric).\n",
        "Configuramos Grid Search utilizando GridSearchCV. La validación cruzada con 5 pliegues (cv=5) se utiliza para evaluar cada combinación de hiperparámetros.\n",
        "Realizamos Grid Search para encontrar los mejores hiperparámetros para el modelo KNN."
      ],
      "metadata": {
        "id": "3RuOmfwZBDjI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir la cuadrícula de hiperparámetros para KNN\n",
        "knn_param_grid = {\n",
        "    'n_neighbors': [3, 5, 7, 9],\n",
        "    'weights': ['uniform', 'distance'],\n",
        "    'metric': ['euclidean', 'manhattan']\n",
        "}\n",
        "\n",
        "# Inicializar el clasificador KNN\n",
        "knn_classifier = KNeighborsClassifier()\n",
        "\n",
        "# Configurar Grid Search para KNN\n",
        "grid_search_knn = GridSearchCV(knn_classifier, knn_param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "# Realizar Grid Search para KNN\n",
        "grid_search_knn.fit(X_scaled, y)\n",
        "\n",
        "# Obtener los mejores hiperparámetros para KNN\n",
        "best_params_knn = grid_search_knn.best_params_\n",
        "print(\"Mejores Hiperparámetros para KNN:\", best_params_knn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmiRLoLMAv_7",
        "outputId": "4ce1bfeb-a650-4e44-9eec-0d7ffe3a1909"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mejores Hiperparámetros para KNN: {'metric': 'manhattan', 'n_neighbors': 7, 'weights': 'distance'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Optimización de Hiperparámetros (Continuación)\n",
        "Grid Search para SVM\n",
        "\n",
        "Definimos una cuadrícula de hiperparámetros para SVM, incluyendo el parámetro de regularización (C), el tipo de kernel (kernel) y el coeficiente del kernel (gamma).\n",
        "Configuramos Grid Search utilizando GridSearchCV. La validación cruzada con 5 pliegues (cv=5) se utiliza para evaluar cada combinación de hiperparámetros.\n",
        "Realizamos Grid Search para encontrar los mejores hiperparámetros para el modelo SVM."
      ],
      "metadata": {
        "id": "96UaKwcMBeCu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir la cuadrícula de hiperparámetros para SVM\n",
        "svm_param_grid = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'kernel': ['linear', 'rbf'],\n",
        "    'gamma': ['scale', 'auto']\n",
        "}\n",
        "\n",
        "# Inicializar el clasificador SVM\n",
        "svm_classifier = SVC(random_state=42)\n",
        "\n",
        "# Configurar Grid Search para SVM\n",
        "grid_search_svm = GridSearchCV(svm_classifier, svm_param_grid, cv=5, scoring='accuracy')\n",
        "\n",
        "# Realizar Grid Search para SVM\n",
        "grid_search_svm.fit(X_scaled, y)\n",
        "\n",
        "# Obtener los mejores hiperparámetros para SVM\n",
        "best_params_svm = grid_search_svm.best_params_\n",
        "print(\"Mejores Hiperparámetros para SVM:\", best_params_svm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKKPDn8uAvxL",
        "outputId": "30f1ea60-633c-4921-b85b-26e334c88751"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mejores Hiperparámetros para SVM: {'C': 10, 'gamma': 'auto', 'kernel': 'rbf'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Randomized Search para Naive Bayes\n",
        "\n",
        "Definimos una distribución de hiperparámetros para Naive Bayes, incluyendo el parámetro de suavizado (var_smoothing). Utilizamos una escala logarítmica para explorar diferentes órdenes de magnitud.\n",
        "Configuramos Randomized Search utilizando RandomizedSearchCV. La validación cruzada con 5 pliegues (cv=5) se utiliza para evaluar cada combinación de hiperparámetros. Realizamos 100 iteraciones (n_iter=100) para explorar diversas combinaciones de hiperparámetros de manera eficiente.\n",
        "Realizamos Randomized Search para encontrar los mejores hiperparámetros para el modelo Naive Bayes."
      ],
      "metadata": {
        "id": "0oppDEdZCs91"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Definir la distribución de hiperparámetros para Naive Bayes\n",
        "naive_bayes_param_dist = {\n",
        "    'var_smoothing': np.logspace(0, -9, num=100)\n",
        "}\n",
        "\n",
        "# Inicializar el clasificador Naive Bayes\n",
        "naive_bayes_classifier = GaussianNB()\n",
        "\n",
        "# Configurar Randomized Search para Naive Bayes\n",
        "randomized_search_naive_bayes = RandomizedSearchCV(naive_bayes_classifier, param_distributions=naive_bayes_param_dist,\n",
        "                                                   n_iter=100, cv=5, scoring='accuracy', random_state=42)\n",
        "\n",
        "# Realizar Randomized Search para Naive Bayes\n",
        "randomized_search_naive_bayes.fit(X_scaled, y)\n",
        "\n",
        "# Obtener los mejores hiperparámetros para Naive Bayes\n",
        "best_params_naive_bayes = randomized_search_naive_bayes.best_params_\n",
        "print(\"Mejores Hiperparámetros para Naive Bayes:\", best_params_naive_bayes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3AbodwUhAvs7",
        "outputId": "39356e9d-f32b-4f09-f6fb-0172ea0b4d69"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mejores Hiperparámetros para Naive Bayes: {'var_smoothing': 0.008111308307896872}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ensamble de Modelos (Votación Mayoritaria)\n",
        "\n",
        "La votación mayoritaria es una técnica de ensamble que combina las predicciones de varios modelos individuales y emite una predicción final basada en la mayoría de votos. En este caso, utilizaremos los modelos KNN, SVM y Naive Bayes para formar nuestro ensamble.\n",
        "Inicialización de Modelos: Creamos instancias de los modelos KNN, SVM y Naive Bayes con los mejores hiperparámetros encontrados durante la optimización.\n",
        "Configuración del Ensamble: Configuramos un clasificador de votación mayoritaria (VotingClassifier) que incluye los modelos KNN, SVM y Naive Bayes. Utilizamos el enfoque de 'hard' voting, donde la clase predicha es la clase mayoritaria votada por los clasificadores individuales.\n",
        "Entrenamiento del Ensamble: Entrenamos el ensamble de modelos utilizando los datos escalados (X_scaled y y).\n",
        "Predicciones y Evaluación: Hacemos predicciones en el conjunto de prueba y evaluamos el rendimiento del ensamble utilizando la matriz de confusión y el informe de clasificación."
      ],
      "metadata": {
        "id": "07vN-7h6DLbP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Inicializar los modelos con los mejores hiperparámetros encontrados\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=best_params_knn['n_neighbors'],\n",
        "                                      weights=best_params_knn['weights'],\n",
        "                                      metric=best_params_knn['metric'])\n",
        "\n",
        "svm_classifier = SVC(C=best_params_svm['C'],\n",
        "                     kernel=best_params_svm['kernel'],\n",
        "                     gamma=best_params_svm['gamma'],\n",
        "                     random_state=42)\n",
        "\n",
        "naive_bayes_classifier = GaussianNB(var_smoothing=best_params_naive_bayes['var_smoothing'])\n",
        "\n",
        "# Configurar el ensamble de modelos usando Votación Mayoritaria\n",
        "voting_classifier = VotingClassifier(estimators=[\n",
        "    ('knn', knn_classifier),\n",
        "    ('svm', svm_classifier),\n",
        "    ('naive_bayes', naive_bayes_classifier)\n",
        "], voting='hard')\n",
        "# En 'hard' voting, la clase predicha es la clase mayoritaria votada por los clasificadores individuales.\n",
        "\n",
        "# Entrenar el ensamble de modelos\n",
        "voting_classifier.fit(X_scaled, y)\n",
        "\n",
        "# Realizar predicciones en el conjunto de prueba\n",
        "y_pred_ensemble = voting_classifier.predict(X_test)\n",
        "\n",
        "# Evaluar el rendimiento del ensamble de modelos\n",
        "conf_matrix_ensemble = confusion_matrix(y_test, y_pred_ensemble)\n",
        "class_report_ensemble = classification_report(y_test, y_pred_ensemble)\n",
        "\n",
        "# Imprimir la matriz de confusión y el informe de clasificación del ensamble de modelos\n",
        "print(\"Matriz de Confusión (Ensamble - Votación Mayoritaria):\")\n",
        "print(conf_matrix_ensemble)\n",
        "print(\"\\nInforme de Clasificación (Ensamble - Votación Mayoritaria):\")\n",
        "print(class_report_ensemble)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eble8DAIAvpV",
        "outputId": "212934db-a2a6-4bc9-8c53-f5bab4f7c71e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matriz de Confusión (Ensamble - Votación Mayoritaria):\n",
            "[[187  19]\n",
            " [ 15 183]]\n",
            "\n",
            "Informe de Clasificación (Ensamble - Votación Mayoritaria):\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.91      0.92       206\n",
            "           1       0.91      0.92      0.92       198\n",
            "\n",
            "    accuracy                           0.92       404\n",
            "   macro avg       0.92      0.92      0.92       404\n",
            "weighted avg       0.92      0.92      0.92       404\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resumen del Proyecto:\n",
        "Carga de Datos: Comenzamos importando el conjunto de datos desde un archivo CSV y exploramos su estructura para entender mejor las características disponibles.\n",
        "\n",
        "Preprocesamiento de Datos: Eliminamos columnas innecesarias y convertimos las etiquetas de destino en valores numéricos para preparar los datos para el entrenamiento del modelo. También dividimos los datos en conjuntos de entrenamiento y prueba, y escalamos las características numéricas para algunos modelos.\n",
        "\n",
        "Modelos Individuales: Entrenamos modelos de aprendizaje automático individuales, incluyendo KNN, SVM y Naive Bayes. Optimizamos los hiperparámetros de estos modelos utilizando técnicas como Grid Search y Randomized Search.\n",
        "\n",
        "Ensamble de Modelos: Creamos un ensamble de modelos utilizando la técnica de Votación Mayoritaria. Este ensamble combina las predicciones de los modelos KNN, SVM y Naive Bayes para mejorar la precisión general del sistema.\n",
        "\n",
        "Evaluación del Rendimiento: Utilizamos la matriz de confusión y el informe de clasificación para evaluar el rendimiento del ensamble de modelos. Estas métricas nos proporcionan una visión detallada de cómo el modelo clasifica las canciones en función de las preferencias del usuario."
      ],
      "metadata": {
        "id": "N1W0BkSTDql9"
      }
    }
  ]
}